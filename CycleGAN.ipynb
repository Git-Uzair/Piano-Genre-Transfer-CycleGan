{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import pretty_midi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "def save_ckp(state, is_best, checkpoint_dir, best_model_dir):\n",
    "    f_path = checkpoint_dir / 'checkpoint.pt'\n",
    "    torch.save(state, f_path)\n",
    "    if is_best:\n",
    "        best_fpath = best_model_dir / 'best_model.pt'\n",
    "        shutil.copyfile(f_path, best_fpath)\n",
    "        \n",
    "def load_ckp(checkpoint_fpath, model, optimizer):\n",
    "    checkpoint = torch.load(checkpoint_fpath)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    #optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    return model, optimizer, checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving array to midi and stuff\n",
    "def set_piano_roll_to_instrument(piano_roll, instrument, velocity=100, tempo=120.0, beat_resolution=16):\n",
    "    # Calculate time per pixel\n",
    "    tpp = 60.0 / tempo / float(beat_resolution)\n",
    "    threshold = 60.0 / tempo / 4\n",
    "    phrase_end_time = 60.0 / tempo * 4 * piano_roll.shape[0]\n",
    "    # Create piano_roll_search that captures note onsets and offsets\n",
    "    piano_roll = piano_roll.reshape((piano_roll.shape[0] * piano_roll.shape[1], piano_roll.shape[2]))\n",
    "    piano_roll_diff = np.concatenate((np.zeros((1, 128), dtype=int), piano_roll, np.zeros((1, 128), dtype=int)))\n",
    "    piano_roll_search = np.diff(piano_roll_diff.astype(int), axis=0)\n",
    "    # Iterate through all possible(128) pitches\n",
    "\n",
    "    for note_num in range(128):\n",
    "        # Search for notes\n",
    "        start_idx = (piano_roll_search[:, note_num] > 0).nonzero()\n",
    "        start_time = list(tpp * (start_idx[0].astype(float)))\n",
    "        # print('start_time:', start_time)\n",
    "        # print(len(start_time))\n",
    "        end_idx = (piano_roll_search[:, note_num] < 0).nonzero()\n",
    "        end_time = list(tpp * (end_idx[0].astype(float)))\n",
    "        # print('end_time:', end_time)\n",
    "        # print(len(end_time))\n",
    "        duration = [pair[1] - pair[0] for pair in zip(start_time, end_time)]\n",
    "        # print('duration each note:', duration)\n",
    "        # print(len(duration))\n",
    "\n",
    "        temp_start_time = [i for i in start_time]\n",
    "        temp_end_time = [i for i in end_time]\n",
    "\n",
    "        for i in range(len(start_time)):\n",
    "            # print(start_time)\n",
    "            if start_time[i] in temp_start_time and i != len(start_time) - 1:\n",
    "                # print('i and start_time:', i, start_time[i])\n",
    "                t = []\n",
    "                current_idx = temp_start_time.index(start_time[i])\n",
    "                for j in range(current_idx + 1, len(temp_start_time)):\n",
    "                    # print(j, temp_start_time[j])\n",
    "                    if temp_start_time[j] < start_time[i] + threshold and temp_end_time[j] <= start_time[i] + threshold:\n",
    "                        # print('popped start time:', temp_start_time[j])\n",
    "                        t.append(j)\n",
    "                        # print('popped temp_start_time:', t)\n",
    "                for _ in t:\n",
    "                    temp_start_time.pop(t[0])\n",
    "                    temp_end_time.pop(t[0])\n",
    "                # print('popped temp_start_time:', temp_start_time)\n",
    "\n",
    "        start_time = temp_start_time\n",
    "        # print('After checking, start_time:', start_time)\n",
    "        # print(len(start_time))\n",
    "        end_time = temp_end_time\n",
    "        # print('After checking, end_time:', end_time)\n",
    "        # print(len(end_time))\n",
    "        duration = [pair[1] - pair[0] for pair in zip(start_time, end_time)]\n",
    "        # print('After checking, duration each note:', duration)\n",
    "        # print(len(duration))\n",
    "\n",
    "        if len(end_time) < len(start_time):\n",
    "            d = len(start_time) - len(end_time)\n",
    "            start_time = start_time[:-d]\n",
    "        # Iterate through all the searched notes\n",
    "        for idx in range(len(start_time)):\n",
    "            if duration[idx] >= threshold:\n",
    "                # Create an Note object with corresponding note number, start time and end time\n",
    "                note = pretty_midi.Note(velocity=velocity, pitch=note_num, start=start_time[idx], end=end_time[idx])\n",
    "                # Add the note to the Instrument object\n",
    "                instrument.notes.append(note)\n",
    "            else:\n",
    "                if start_time[idx] + threshold <= phrase_end_time:\n",
    "                    # Create an Note object with corresponding note number, start time and end time\n",
    "                    note = pretty_midi.Note(velocity=velocity, pitch=note_num, start=start_time[idx],\n",
    "                                            end=start_time[idx] + threshold)\n",
    "                else:\n",
    "                    # Create an Note object with corresponding note number, start time and end time\n",
    "                    note = pretty_midi.Note(velocity=velocity, pitch=note_num, start=start_time[idx],\n",
    "                                            end=phrase_end_time)\n",
    "                # Add the note to the Instrument object\n",
    "                instrument.notes.append(note)\n",
    "    # Sort the notes by their start time\n",
    "    instrument.notes.sort(key=lambda note: note.start)\n",
    "    # print(max([i.end for i in instrument.notes]))\n",
    "    # print('tpp, threshold, phrases_end_time:', tpp, threshold, phrase_end_time)\n",
    "\n",
    "def write_piano_rolls_to_midi(piano_rolls, program_nums=None, is_drum=None, filename='test.mid', velocity=100,\n",
    "                              tempo=120.0, beat_resolution=24):\n",
    "    if len(piano_rolls) != len(program_nums) or len(piano_rolls) != len(is_drum):\n",
    "        print(\"Error: piano_rolls and program_nums have different sizes...\")\n",
    "        return False\n",
    "    if not program_nums:\n",
    "        program_nums = [0, 0, 0]\n",
    "    if not is_drum:\n",
    "        is_drum = [False, False, False]\n",
    "    # Create a PrettyMIDI object\n",
    "    midi = pretty_midi.PrettyMIDI(initial_tempo=tempo)\n",
    "    # Iterate through all the input instruments\n",
    "    for idx in range(len(piano_rolls)):\n",
    "        # Create an Instrument object\n",
    "        instrument = pretty_midi.Instrument(program=program_nums[idx], is_drum=is_drum[idx])\n",
    "        # Set the piano roll to the Instrument object\n",
    "        set_piano_roll_to_instrument(piano_rolls[idx], instrument, velocity, tempo, beat_resolution)\n",
    "        # Add the instrument to the PrettyMIDI object\n",
    "        midi.instruments.append(instrument)\n",
    "    # Write out the MIDI data\n",
    "    midi.write(filename)\n",
    "\n",
    "def save_midis(bars, file_path, tempo=80.0):\n",
    "    padded_bars = np.concatenate((np.zeros((bars.shape[0], bars.shape[1], 24, bars.shape[3])), bars,\n",
    "                                  np.zeros((bars.shape[0], bars.shape[1], 20, bars.shape[3]))), axis=2)\n",
    "    pause = np.zeros((bars.shape[0], 64, 128, bars.shape[3]))\n",
    "    images_with_pause = padded_bars\n",
    "    images_with_pause = images_with_pause.reshape(-1, 64, padded_bars.shape[2], padded_bars.shape[3])\n",
    "    images_with_pause_list = []\n",
    "    for ch_idx in range(padded_bars.shape[3]):\n",
    "        images_with_pause_list.append(images_with_pause[:, :, :, ch_idx].reshape(images_with_pause.shape[0],\n",
    "                                                                                 images_with_pause.shape[1],\n",
    "                                                                                 images_with_pause.shape[2]))\n",
    "    # write_midi.write_piano_rolls_to_midi(images_with_pause_list, program_nums=[33, 0, 25, 49, 0],\n",
    "    #                                      is_drum=[False, True, False, False, False], filename=file_path, tempo=80.0)\n",
    "    write_piano_rolls_to_midi(images_with_pause_list, program_nums=[0], is_drum=[False], filename=file_path,\n",
    "                                         tempo=tempo, beat_resolution=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#loading data and stuff\n",
    "def npy_loader(path):\n",
    "    sample = torch.from_numpy(np.load(path))\n",
    "    return sample\n",
    "\n",
    "#X_train DATASET, X_TEST DATASET\n",
    "X_TRAIN = datasets.DatasetFolder(\n",
    "    root='classic_piano_x_train',\n",
    "    loader=npy_loader,\n",
    "    extensions=(\".npy\")\n",
    ")\n",
    "\n",
    "X_TEST = datasets.DatasetFolder(\n",
    "    root='classic_piano_x_test',\n",
    "    loader=npy_loader,\n",
    "    extensions=(\".npy\")\n",
    ")\n",
    "\n",
    "Y_TRAIN = datasets.DatasetFolder(\n",
    "    root='jazz_piano_y_train',\n",
    "    loader=npy_loader,\n",
    "    extensions=(\".npy\")\n",
    ")\n",
    "\n",
    "Y_TEST = datasets.DatasetFolder(\n",
    "    root='jazz_piano_y_test',\n",
    "    loader=npy_loader,\n",
    "    extensions=(\".npy\")\n",
    ")\n",
    "\n",
    "dataloader_X= DataLoader(dataset=X_TRAIN, batch_size=16, shuffle=True, num_workers=0)\n",
    "test_dataloader_X = DataLoader(dataset=X_TEST, batch_size=16, shuffle=True, num_workers=0)\n",
    "\n",
    "dataloader_Y = DataLoader(dataset=Y_TRAIN, batch_size=16, shuffle=True, num_workers=0)\n",
    "test_dataloader_Y = DataLoader(dataset=Y_TEST, batch_size=16, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONV helper function\n",
    "def conv(in_channels, out_channels, kernel_size, stride, padding=1, instance_norm=False):\n",
    "    \"\"\"Creates a convolutional layer, with optional Instance normalization.\n",
    "    \"\"\"\n",
    "    layers = []\n",
    "    conv_layer = nn.Conv2d(in_channels, out_channels, \n",
    "                           kernel_size, stride, padding, bias=False)\n",
    "    \n",
    "    # append conv layer\n",
    "    layers.append(conv_layer)\n",
    "\n",
    "    if instance_norm:\n",
    "        # append batchnorm layer\n",
    "        layers.append(nn.InstanceNorm2d(out_channels))\n",
    "     \n",
    "    # using Sequential container\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DECONV helper function\n",
    "def deconv(in_channels, out_channels, kernel_size, stride=2, padding=1,output_padding=1, instance_norm=False):\n",
    "    \"\"\"Creates a transposed-convolutional layer, with optional instance normalization.\n",
    "    \"\"\"\n",
    "    # create a sequence of transpose + optional batch norm layers\n",
    "    layers = []\n",
    "    transpose_conv_layer = nn.ConvTranspose2d(in_channels, out_channels, \n",
    "                                              kernel_size, stride, padding,output_padding, bias=False)\n",
    "    # append transpose convolutional layer\n",
    "    layers.append(transpose_conv_layer)\n",
    "    \n",
    "    if instance_norm:\n",
    "        # append batchnorm layer\n",
    "        layers.append(nn.InstanceNorm2d(out_channels))\n",
    "        \n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 Generators \n",
    "#A-B generator and B-A generator\n",
    "#1 discriminator associated with each generator\n",
    "#A-B Discriminator and B-A Discriminator\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,conv_dim=64):\n",
    "        \n",
    "        super(Discriminator,self).__init__()\n",
    "        \n",
    "        self.conv_dim = conv_dim\n",
    "        \n",
    "        self.conv_layer_1 = conv(1,out_channels=conv_dim,kernel_size=4,stride=2,padding=1, instance_norm=False)\n",
    "        \n",
    "        self.conv_layer_2 = conv(conv_dim,out_channels=conv_dim*4,kernel_size=4,stride=2,padding=1, instance_norm=True)\n",
    "        \n",
    "        self.conv_layer_3 = conv(conv_dim*4,out_channels=1,kernel_size=1,stride=1,padding=0, instance_norm=False)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        \n",
    "        output = F.leaky_relu(self.conv_layer_1(x),0.2)\n",
    "        \n",
    "        output = F.leaky_relu(self.conv_layer_2(output),0.2)\n",
    "        \n",
    "        output = self.conv_layer_3(output)\n",
    "       \n",
    "        return output\n",
    "        \n",
    "\n",
    "# discrim = Discriminator(64)\n",
    "# print(discrim)\n",
    "       \n",
    "\n",
    "# data = torch.randn(1,1,64,84)\n",
    "# print(discrim(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# residual block class\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"Defines a residual block.\n",
    "       This adds an input x to a convolutional layer (applied to x) with the same size input and output.\n",
    "       These blocks allow a model to learn an effective transformation from one domain to another.\n",
    "    \"\"\"\n",
    "    def __init__(self, conv_dim=256):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        # conv_dim = number of inputs\n",
    "        \n",
    "        # define two convolutional layers + batch normalization that will act as our residual function, F(x)\n",
    "        # layers should have the same shape input as output; I suggest a kernel_size of 3\n",
    "        \n",
    "        self.conv_layer1 = conv(in_channels=conv_dim, out_channels=conv_dim, \n",
    "                                kernel_size=3, stride=1, padding=1, instance_norm=True)\n",
    "        \n",
    "        self.conv_layer2 = conv(in_channels=conv_dim, out_channels=conv_dim, \n",
    "                               kernel_size=3, stride=1, padding=1, instance_norm=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "       \n",
    "        out_1 = F.relu(self.conv_layer1(x))\n",
    "       \n",
    "        out_2 = F.relu(x + self.conv_layer2(out_1))\n",
    "        \n",
    "        out_3 = x+out_2\n",
    "        return out_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Res_layers(number,conv_dim=256):\n",
    "    layers = []\n",
    "    for i in range(number):\n",
    "        layers.append(ResidualBlock(conv_dim))\n",
    "        \n",
    "    return nn.Sequential(*layers)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self,res_blocks,conv_dim=64):\n",
    "        \n",
    "        super(Generator,self).__init__()\n",
    "        \n",
    "        self.conv_dim = conv_dim\n",
    "        \n",
    "        self.conv_layer_1 = conv(1,self.conv_dim,kernel_size=7,stride=1,padding=3,instance_norm=True)\n",
    "      \n",
    "        \n",
    "        self.conv_layer_2 = conv(conv_dim,self.conv_dim*2,kernel_size=3,stride=2,padding=1,instance_norm=True)\n",
    "        \n",
    "        \n",
    "        self.conv_layer_3 = conv(self.conv_dim*2,self.conv_dim*4,kernel_size=3,stride=2,padding=1,instance_norm=True)\n",
    "        \n",
    "        \n",
    "        self.res_layers = Res_layers(res_blocks,256)\n",
    "        \n",
    "        self.deconv_layer_1 = deconv(self.conv_dim*4,self.conv_dim*2,kernel_size=3,stride=2,padding=1,instance_norm=True)\n",
    "        \n",
    "        self.deconv_layer_2 = deconv(self.conv_dim*2,self.conv_dim,kernel_size=3,stride=2,padding=1,instance_norm=True)\n",
    "        \n",
    "        self.deconv_layer_3= deconv(self.conv_dim,1,kernel_size=7,stride=1,padding=3,output_padding=0,instance_norm=False)\n",
    "        \n",
    "    \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = F.relu(self.conv_layer_1(x))\n",
    "       \n",
    "        x = F.relu(self.conv_layer_2(x))\n",
    "        \n",
    "        x = F.relu(self.conv_layer_3(x))\n",
    "        \n",
    "        x = self.res_layers(x)\n",
    "       \n",
    "        x = F.relu(self.deconv_layer_1(x))\n",
    "        \n",
    "        x = F.relu(self.deconv_layer_2(x))\n",
    "        \n",
    "        x = F.sigmoid(self.deconv_layer_3(x))\n",
    "        \n",
    "        \n",
    "        return x\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(g_conv_dim=64, d_conv_dim=64, n_res_blocks=10):\n",
    "    \"\"\"Builds the generators and discriminators.\"\"\"\n",
    "    \n",
    "    # Instantiate generators\n",
    "    G_XtoY = Generator(res_blocks=n_res_blocks,conv_dim=g_conv_dim)\n",
    "    G_YtoX = Generator(res_blocks=n_res_blocks,conv_dim=g_conv_dim)\n",
    "    # Instantiate discriminators\n",
    "    D_X = Discriminator(conv_dim=d_conv_dim)\n",
    "    D_Y = Discriminator(conv_dim=d_conv_dim)\n",
    "\n",
    "    # move models to GPU, if available\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cpu\")\n",
    "        G_XtoY.to(device)\n",
    "        G_YtoX.to(device)\n",
    "        D_X.to(device)\n",
    "        D_Y.to(device)\n",
    "        print('Models moved to CPU.')\n",
    "    else:\n",
    "        print('Only CPU available.')\n",
    "\n",
    "    return G_XtoY, G_YtoX, D_X, D_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models moved to CPU.\n"
     ]
    }
   ],
   "source": [
    "G_XtoY, G_YtoX, D_X, D_Y = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pytorch_modelsize import SizeEstimator\n",
    "\n",
    "# se = SizeEstimator(D_X.to(\"cpu\"), input_size=(16,1,64,84))\n",
    "# print(se.estimate_size())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (conv_layer_1): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (conv_layer_2): Sequential(\n",
      "    (0): Conv2d(64, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  )\n",
      "  (conv_layer_3): Sequential(\n",
      "    (0): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(D_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#losses\n",
    "def real_mse_loss(D_out):\n",
    "    # how close is the produced output from being \"real\"?\n",
    "    return torch.mean((D_out-1)**2)\n",
    "\n",
    "def fake_mse_loss(D_out):\n",
    "    # how close is the produced output from being \"fake\"?\n",
    "    return torch.mean(D_out**2)\n",
    "\n",
    "def cycle_consistency_loss(real_im, reconstructed_im, lambda_weight):\n",
    "    # calculate reconstruction loss \n",
    "    # as absolute value difference between the real and reconstructed images\n",
    "    reconstr_loss = torch.mean(torch.abs(real_im - reconstructed_im))\n",
    "    # return weighted loss\n",
    "    return lambda_weight*reconstr_loss\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'G_XtoY' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-cb50a453a3f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.999\u001b[0m \u001b[1;31m# default value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mg_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG_XtoY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG_YtoX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Get generator parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Create optimizers for the generators and discriminators\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'G_XtoY' is not defined"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# hyperparams for Adam optimizer\n",
    "lr=0.0002\n",
    "beta1=0.5\n",
    "beta2=0.999 # default value\n",
    "\n",
    "g_params = list(G_XtoY.parameters()) + list(G_YtoX.parameters())  # Get generator parameters\n",
    "\n",
    "# Create optimizers for the generators and discriminators\n",
    "g_optimizer = optim.Adam(g_params, lr, [beta1, beta2])\n",
    "d_x_optimizer = optim.Adam(D_X.parameters(), lr, [beta1, beta2])\n",
    "d_y_optimizer = optim.Adam(D_Y.parameters(), lr, [beta1, beta2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING LOOP\n",
    "\n",
    "\n",
    "# train the network\n",
    "\n",
    "def training_loop(dataloader_X, dataloader_Y, test_dataloader_X, test_dataloader_Y, \n",
    "                  n_epochs=1000):\n",
    "    reconstructed_x_loss_min = math.inf\n",
    "    reconstructed_y_loss_min = math.inf\n",
    "    print_every=10\n",
    "    \n",
    "    # keep track of losses over time\n",
    "    losses = []\n",
    "    \n",
    "    test_iter_X = iter(test_dataloader_X)\n",
    "    test_iter_Y = iter(test_dataloader_Y)\n",
    "\n",
    "    # Get some fixed data from domains X and Y for sampling. that allow us to inspect the model's performance.\n",
    "    fixed_X = test_iter_X.next()[0]\n",
    "    fixed_Y = test_iter_Y.next()[0]\n",
    "\n",
    "\n",
    "    # batches per epoch\n",
    "    iter_X = iter(dataloader_X)\n",
    "    iter_Y = iter(dataloader_Y)\n",
    "    batches_per_epoch = min(len(iter_X), len(iter_Y))\n",
    "\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        \n",
    "        \n",
    "        # Reset iterators for each epoch\n",
    "        if epoch % batches_per_epoch == 0:\n",
    "            iter_X = iter(dataloader_X)\n",
    "            iter_Y = iter(dataloader_Y)\n",
    "\n",
    "        data_X, _ = iter_X.next()\n",
    "        data_Y, _ = iter_Y.next()\n",
    "        \n",
    "        # move images to GPU if available (otherwise stay on CPU)\n",
    "        device = torch.device(\"cpu\")\n",
    "        data_X = data_X.to(device)\n",
    "        data_Y = data_Y.to(device)\n",
    "        \n",
    "        data_X = data_X.permute(0,3,1,2).float()\n",
    "        data_Y = data_Y.permute(0,3,1,2).float()\n",
    "\n",
    "        # ============================================\n",
    "        #            TRAIN THE DISCRIMINATORS\n",
    "        # ============================================\n",
    "\n",
    "        ##   First: D_X, real and fake loss components   ##\n",
    "\n",
    "        # Train with real images\n",
    "        d_x_optimizer.zero_grad()\n",
    "\n",
    "        # 1. Compute the discriminator losses on real data from DOMAINN+ X\n",
    "        out_x = D_X(data_X)\n",
    "        D_X_real_loss = real_mse_loss(out_x)\n",
    "        \n",
    "        # Train with fake X domain generated from domain Y\n",
    "        \n",
    "        # 2. Generate fake data that look like domain X based on real data in domain Y\n",
    "        fake_X = G_YtoX(data_Y)\n",
    "\n",
    "        # 3. Compute the fake loss for D_X\n",
    "        out_x = D_X(fake_X)\n",
    "        D_X_fake_loss = fake_mse_loss(out_x)\n",
    "        \n",
    "\n",
    "        # 4. Compute the total loss and perform backprop\n",
    "        d_x_loss = D_X_real_loss + D_X_fake_loss\n",
    "        d_x_loss.backward()\n",
    "        d_x_optimizer.step()\n",
    "\n",
    "        \n",
    "        ##   Second: D_Y, real and fake loss components   ##\n",
    "        \n",
    "        # Train with real data\n",
    "        d_y_optimizer.zero_grad()\n",
    "        \n",
    "        # 1. Compute the discriminator losses on real data from DOMAIN Y\n",
    "        out_y = D_Y(data_Y)\n",
    "        D_Y_real_loss = real_mse_loss(out_y)\n",
    "        \n",
    "        # Train with fake images\n",
    "\n",
    "        # 2. Generate fake data that look like domain Y based on real data in domain X\n",
    "        fake_Y = G_XtoY(data_X)\n",
    "\n",
    "        # 3. Compute the fake loss for D_Y\n",
    "        out_y = D_Y(fake_Y)\n",
    "        D_Y_fake_loss = fake_mse_loss(out_y)\n",
    "\n",
    "        # 4. Compute the total loss and perform backprop\n",
    "        d_y_loss = D_Y_real_loss + D_Y_fake_loss\n",
    "        d_y_loss.backward()\n",
    "        d_y_optimizer.step()\n",
    "\n",
    "\n",
    "        # =========================================\n",
    "        #            TRAIN THE GENERATORS\n",
    "        # =========================================\n",
    "\n",
    "        ##    First: generate fake X data and reconstructed Y data   ##\n",
    "        g_optimizer.zero_grad()\n",
    "\n",
    "        # 1. Generate fake images that look like domain X based on real images in domain Y\n",
    "        fake_X = G_YtoX(data_Y)\n",
    "\n",
    "        # 2. Compute the generator loss based on domain X\n",
    "        out_x = D_X(fake_X)\n",
    "        g_YtoX_loss = real_mse_loss(out_x)\n",
    "\n",
    "        # 3. Create a reconstructed y\n",
    "        # 4. Compute the cycle consistency loss (the reconstruction loss)\n",
    "        reconstructed_Y = G_XtoY(fake_X)\n",
    "        reconstructed_y_loss = cycle_consistency_loss(data_Y, reconstructed_Y, lambda_weight=10)\n",
    "\n",
    "\n",
    "        ##    Second: generate fake Y images and reconstructed X images    ##\n",
    "\n",
    "        # 1. Generate fake images that look like domain Y based on real images in domain X\n",
    "        fake_Y = G_XtoY(data_X)\n",
    "\n",
    "        # 2. Compute the generator loss based on domain Y\n",
    "        out_y = D_Y(fake_Y)\n",
    "        g_XtoY_loss = real_mse_loss(out_y)\n",
    "\n",
    "        # 3. Create a reconstructed x\n",
    "        # 4. Compute the cycle consistency loss (the reconstruction loss)\n",
    "        reconstructed_X = G_YtoX(fake_Y)\n",
    "        reconstructed_x_loss = cycle_consistency_loss(data_X, reconstructed_X, lambda_weight=10)\n",
    "\n",
    "        # 5. Add up all generator and reconstructed losses and perform backprop\n",
    "        g_total_loss = g_YtoX_loss + g_XtoY_loss + reconstructed_y_loss + reconstructed_x_loss\n",
    "        g_total_loss.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "\n",
    "        # Print the log info\n",
    "        if epoch % print_every == 0:\n",
    "            # append real and fake discriminator losses and the generator loss\n",
    "            losses.append((d_x_loss.item(), d_y_loss.item(), g_total_loss.item()))\n",
    "            print('Epoch [{:5d}/{:5d}] | d_X_loss: {:6.4f} | d_Y_loss: {:6.4f} | g_total_loss: {:6.4f}'.format(\n",
    "                    epoch, n_epochs, d_x_loss.item(), d_y_loss.item(), g_total_loss.item()))\n",
    "\n",
    "            \n",
    "#         sample_every=100\n",
    "        # Save the generated samples\n",
    "#         if epoch % sample_every == 0:\n",
    "#             G_YtoX.eval() # set generators to eval mode for sample generation\n",
    "#             G_XtoY.eval()\n",
    "#             save_samples(epoch, fixed_Y, fixed_X, G_YtoX, G_XtoY, batch_size=16)\n",
    "#             G_YtoX.train()\n",
    "#             G_XtoY.train()\n",
    "\n",
    "        #uncomment these lines, if you want to save your model\n",
    "#          checkpoint_every=100\n",
    "#         # Save the model parameters\n",
    "        if reconstructed_x_loss < reconstructed_x_loss_min:\n",
    "            reconstructed_x_loss_min=reconstructed_x_loss\n",
    "            checkpoint = {\n",
    "                'epoch': epoch+1,\n",
    "                'state_dict': G_XtoY.state_dict(),\n",
    "                'optimizer': g_optimizer.state_dict(),\n",
    "                'minxloss': reconstructed_x_loss_min\n",
    "            }\n",
    "            \n",
    "            #save_ckp(checkpoint,True,\"checkpointsGx\",\"modelsGx\")\n",
    "            torch.save(checkpoint,\"XtoY.pt\")\n",
    "            print(\"Generator X-Y saved with Cycle LOSS: \", reconstructed_x_loss_min)\n",
    "            \n",
    "            checkpoint = {\n",
    "                'epoch': epoch+1,\n",
    "                'state_dict': D_X.state_dict(),\n",
    "                'optimizer': d_x_optimizer.state_dict(),\n",
    "            }\n",
    "            \n",
    "            torch.save(checkpoint,\"Dx.pt\")\n",
    "            #save_ckp(checkpoint,True,\"checkpointsDx\",\"modelsDx\")\n",
    "            \n",
    "        \n",
    "        if reconstructed_y_loss < reconstructed_y_loss_min:\n",
    "            reconstructed_y_loss_min=reconstructed_y_loss\n",
    "            checkpoint = {\n",
    "                'epoch': epoch+1,\n",
    "                'state_dict': G_YtoX.state_dict(),\n",
    "                'optimizer': g_optimizer.state_dict(),\n",
    "                'minxloss': reconstructed_y_loss_min\n",
    "            }\n",
    "            torch.save(checkpoint,\"YtoX.pt\")\n",
    "            #save_ckp(checkpoint,True,\"checkpointsGy\",\"modelsGy\")\n",
    "            print(\"Generator Y-X saved with Cycle LOSS: \", reconstructed_y_loss_min)\n",
    "            \n",
    "            checkpoint = {\n",
    "                'epoch': epoch+1,\n",
    "                'state_dict': D_Y.state_dict(),\n",
    "                'optimizer': d_y_optimizer.state_dict(),\n",
    "            }\n",
    "            torch.save(checkpoint,\"Dy.pt\")\n",
    "            #save_ckp(checkpoint,True,\"checkpointsDy\",\"modelsDy\")\n",
    "            \n",
    "            \n",
    "        \n",
    "            \n",
    "        \n",
    "            \n",
    "                \n",
    "        \n",
    "             \n",
    "\n",
    "    return losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator X-Y saved with Cycle LOSS:  tensor(0.0495, grad_fn=<MulBackward0>)\n",
      "Generator Y-X saved with Cycle LOSS:  tensor(0.0589, grad_fn=<MulBackward0>)\n",
      "Generator Y-X saved with Cycle LOSS:  tensor(0.0587, grad_fn=<MulBackward0>)\n",
      "Generator Y-X saved with Cycle LOSS:  tensor(0.0571, grad_fn=<MulBackward0>)\n",
      "Generator X-Y saved with Cycle LOSS:  tensor(0.0492, grad_fn=<MulBackward0>)\n",
      "Generator Y-X saved with Cycle LOSS:  tensor(0.0552, grad_fn=<MulBackward0>)\n",
      "Generator Y-X saved with Cycle LOSS:  tensor(0.0491, grad_fn=<MulBackward0>)\n",
      "Generator X-Y saved with Cycle LOSS:  tensor(0.0404, grad_fn=<MulBackward0>)\n",
      "Generator Y-X saved with Cycle LOSS:  tensor(0.0474, grad_fn=<MulBackward0>)\n",
      "Epoch [   10/  150] | d_X_loss: 0.4827 | d_Y_loss: 0.4629 | g_total_loss: 0.7001\n",
      "Generator Y-X saved with Cycle LOSS:  tensor(0.0415, grad_fn=<MulBackward0>)\n",
      "Generator Y-X saved with Cycle LOSS:  tensor(0.0354, grad_fn=<MulBackward0>)\n",
      "Generator X-Y saved with Cycle LOSS:  tensor(0.0384, grad_fn=<MulBackward0>)\n",
      "Generator Y-X saved with Cycle LOSS:  tensor(0.0351, grad_fn=<MulBackward0>)\n",
      "Generator X-Y saved with Cycle LOSS:  tensor(0.0369, grad_fn=<MulBackward0>)\n",
      "Epoch [   20/  150] | d_X_loss: 0.4877 | d_Y_loss: 0.4751 | g_total_loss: 0.7040\n",
      "Generator X-Y saved with Cycle LOSS:  tensor(0.0360, grad_fn=<MulBackward0>)\n",
      "Generator X-Y saved with Cycle LOSS:  tensor(0.0291, grad_fn=<MulBackward0>)\n",
      "Epoch [   30/  150] | d_X_loss: 0.4924 | d_Y_loss: 0.4593 | g_total_loss: 0.7105\n",
      "Epoch [   40/  150] | d_X_loss: 0.4550 | d_Y_loss: 0.4589 | g_total_loss: 0.7317\n",
      "Epoch [   50/  150] | d_X_loss: 0.4946 | d_Y_loss: 0.4556 | g_total_loss: 0.7539\n",
      "Epoch [   60/  150] | d_X_loss: 0.4666 | d_Y_loss: 0.4143 | g_total_loss: 0.7935\n",
      "Epoch [   70/  150] | d_X_loss: 0.4846 | d_Y_loss: 0.4537 | g_total_loss: 0.6898\n",
      "Generator Y-X saved with Cycle LOSS:  tensor(0.0311, grad_fn=<MulBackward0>)\n",
      "Epoch [   80/  150] | d_X_loss: 0.4806 | d_Y_loss: 0.4692 | g_total_loss: 0.7268\n",
      "Generator X-Y saved with Cycle LOSS:  tensor(0.0278, grad_fn=<MulBackward0>)\n",
      "Epoch [   90/  150] | d_X_loss: 0.4812 | d_Y_loss: 0.4329 | g_total_loss: 0.7523\n",
      "Epoch [  100/  150] | d_X_loss: 0.4627 | d_Y_loss: 0.4591 | g_total_loss: 0.7180\n",
      "Epoch [  110/  150] | d_X_loss: 0.4629 | d_Y_loss: 0.4336 | g_total_loss: 0.7899\n",
      "Epoch [  120/  150] | d_X_loss: 0.4663 | d_Y_loss: 0.4501 | g_total_loss: 0.7318\n",
      "Epoch [  130/  150] | d_X_loss: 0.4951 | d_Y_loss: 0.4702 | g_total_loss: 0.7277\n",
      "Epoch [  140/  150] | d_X_loss: 0.4693 | d_Y_loss: 0.4318 | g_total_loss: 0.7364\n",
      "Epoch [  150/  150] | d_X_loss: 0.4845 | d_Y_loss: 0.4323 | g_total_loss: 0.7266\n"
     ]
    }
   ],
   "source": [
    "losses = training_loop(dataloader_X, dataloader_Y, test_dataloader_X, test_dataloader_Y, n_epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.5160729289054871, 0.4828607738018036, 0.9774311780929565), (0.5277869701385498, 0.49000129103660583, 0.93255615234375), (0.495054692029953, 0.4750649333000183, 0.9728460907936096), (0.49318191409111023, 0.48721519112586975, 0.8967345952987671), (0.4659627676010132, 0.4949831962585449, 0.9031214714050293), (0.5016170740127563, 0.4577341675758362, 0.849012017250061), (0.50105881690979, 0.46250981092453003, 0.897021472454071), (0.5115640163421631, 0.49374228715896606, 0.8116147518157959), (0.5122978091239929, 0.5086577534675598, 0.7753113508224487), (0.47132331132888794, 0.4540477395057678, 0.7623947858810425), (0.5150717496871948, 0.468146950006485, 0.7518098950386047), (0.5280783772468567, 0.4572400450706482, 0.7999032735824585), (0.48093318939208984, 0.5004737973213196, 0.7171396017074585), (0.47028985619544983, 0.4705091416835785, 0.7120597958564758), (0.5312702655792236, 0.4774635434150696, 0.7357356548309326)]\n"
     ]
    }
   ],
   "source": [
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 84, 1])\n"
     ]
    }
   ],
   "source": [
    "x = npy_loader(\"jazz.npy\")\n",
    "x = x.unsqueeze(0)\n",
    "print(x.shape)\n",
    "\n",
    "\n",
    "save_midis(x,\"jazz.mid\")\n",
    "\n",
    "x = G_YtoX(x.permute(0,3,1,2).float())\n",
    "\n",
    "save_midis(x.permute(0,2,3,1).detach().numpy(),\"jazztoclassic.mid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Generator(res_blocks=10)\n",
    "optimizer = optim.Adam(model.parameters(), lr, [beta1, beta2])\n",
    "ckp_path = \"XtoY.pt\"\n",
    "model,_,_= load_ckp(ckp_path, model, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 84, 1])\n"
     ]
    }
   ],
   "source": [
    "x = npy_loader(\"classic.npy\")\n",
    "x = x.unsqueeze(0)\n",
    "print(x.shape)\n",
    "\n",
    "model.eval()\n",
    "save_midis(x,\"classicnew.mid\")\n",
    "\n",
    "x = model(x.permute(0,3,1,2).float())\n",
    "\n",
    "save_midis(x.permute(0,2,3,1).detach().numpy(),\"classicnewTOjazz.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-kernel",
   "language": "python",
   "name": "project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
